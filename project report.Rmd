---
title: "Project report - Recommender system for movies"
author: "Ingrid Brizotti"
output: pdf_document
---

This project builds recommender systems for movies using Item-Based Collaborative Filtering (IBCF) approach to compare users and items.

The idea is to compare these system using just the information if the user watched the movie or not (called binary in this project) and use the rating gave for each user (called rating). Also, compare different approaches for calculate the similarity between users and items. These measures are: 
- cosine distance
- euclidean distance
- Pearson correlation
- Jaccard index


Require package and datasets used
```{r}
library(data.table)
library(ggplot2)
library(recommenderlab)
library(countrycode)

load("~/Desktop/Ryerson/3.Data_Analytics_Capstone/MovieTweetings/latest/ratings.Rda")
load("~/Desktop/Ryerson/3.Data_Analytics_Capstone/MovieTweetings/latest/movies4.Rda")
```

Data preparation
```{r}
# most common movie
t_m <- aggregate(cbind(count = rating) ~ movie_id, 
                 data = ratings, 
                 FUN = function(x){NROW(x)})
# merge
r <- merge(x=ratings, y=t_m ,by="movie_id", all.x=TRUE)

# select movies with more than 50 ratings
r <- r[r$count >= 50,]

# count movies per user
t_m_u <- aggregate(cbind(count_movie = movie_id) ~ user_id, 
                   data = r, 
                   FUN = function(x){NROW(x)})
# merge
r2 <- merge(x=r, y=t_m_u ,by="user_id", all.x=TRUE)

# select users with more than 20 movies
r2 <- r2[r2$count_movie >= 20,]


# delete count and timestamp
r2 <- subset(r2, , -c(rating_timestamp,count,count_movie))

# convert it into a data table
r2 <- data.table(r2)
```


I will start building recommender systems using just the information if the user watched or not the movie. So, 1 if the user rated the movie, and 0 otherwise. 


Binary recommender systems
```{r}
# delete rating
r_binary <- subset(r2, , -c(rating))

# reshape
r_binary[, value := 1]
r_wide <- reshape(data = r_binary,
                  direction = "wide",
                  idvar = "user_id",
                  timevar = "movie_id",
                  v.names = "value",
                  drop = NULL)

# keep only the columns containing ratings
# the user name will be the matrix row names, so we need to store them in the vector_users vector
vector_users <- r_wide[, user_id]
r_wide <- r_wide[ ,user_id := NULL]


# have the column names equal to the item names
setnames(x = r_wide,
         old = names(r_wide),
         new = substring(names(r_wide), 7))

# store the rating matrix within a recommenderlab object: 
# 1) convert r_wide in a matrix 
# 2) set the row names equal to the user names
matrix_wide <- as.matrix(r_wide)
rownames(matrix_wide) <- vector_users

# replace NA for zero
matrix_wide[is.na(matrix_wide)] <- 0
head(matrix_wide[, 1:6])

# coercing matrix_wide into a binary rating matrix 
ratings_matrix <- as(matrix_wide, "binaryRatingMatrix")
ratings_matrix
```

Compare recommender sytems using different approaches to calculate the similarity
```{r}
# split the data into the training and the test set
which_train <- sample(x = c(TRUE, FALSE),
                      size = nrow(ratings_matrix),
                      replace = TRUE,
                      prob = c(0.7, 0.3))
recc_data_train <- ratings_matrix[which_train, ]
recc_data_test <- ratings_matrix[!which_train, ]

percentage_training <- 0.7

# minimum number of movies watched by any user
min(rowCounts(ratings_matrix))
# [1] 20

# keep 15 movies
items_to_keep <- 15

# the rating = 1 (watched the movie) will be considered good to evaluate the model
rating_threshold <- 1

# how many times we want to run the evaluation
n_eval <- 1

eval_sets <- evaluationScheme(data = ratings_matrix, 
                              method = "split",
                              train = percentage_training, 
                              given = items_to_keep, 
                              goodRating =rating_threshold, 
                              k = n_eval) 

models_to_evaluate <- list(
  IBCF_jac = list(name = "IBCF", param = list(method = "jaccard")),
  IBCF_cos = list(name = "IBCF", param = list(method = "cosine")),
  IBCF_cor = list(name = "IBCF", param = list(method = "pearson")),
  IBCF_euc = list(name = "IBCF", param = list(method = "euclidean")),
  
  UBCF_jac = list(name = "UBCF", param = list(method = "jaccard")),
  UBCF_cos = list(name = "UBCF", param = list(method = "cosine")),
  UBCF_cor = list(name = "UBCF", param = list(method = "pearson")),
  UBCF_euc = list(name = "UBCF", param = list(method = "euclidean"))
#  ,random = list(name = "RANDOM", param=NULL)
)

# number of recommendations
n_recommendations <- c(1, 5, seq(10, 30, 5))

# We are ready to run and evaluate the models. 
# The only difference from code 5.evaluate binary CF is now the input method is a list of models
list_results <- evaluate(x = eval_sets, 
                         method = models_to_evaluate,
                         n = n_recommendations)

class(list_results)

# Calculate the ROC curve
plot(list_results, legend = "topleft",ylim = c(0, 0.35)) 
title("ROC curve")

# Calculate the precision and recall
plot(list_results, "prec/rec", legend = "bottomleft")
title("Precision-recall binary models")

# average confusion matrix
avg_matrices <- lapply(list_results, avg)

# IBCF cosine distance
head(avg_matrices$IBCF_cos[,1:8])


# IBCF Pearson correlation
head(avg_matrices$IBCF_cor[, 1:8])

# IBCF jaccard
head(avg_matrices$IBCF_jac[, 1:8])

# IBCF Eucliden
head(avg_matrices$IBCF_euc[, 1:8])

# UBCF cosine distance
head(avg_matrices$UBCF_cos[, 1:8])

# UBCF jaccard
head(avg_matrices$UBCF_jac[, 1:8])
```


Now, I will use the rating information to build the recommender systems.

```{r}
# Data preparation
# reshape
r_wide <- reshape(data = r2,
                  direction = "wide",
                  idvar = "user_id",
                  timevar = "movie_id",
                  drop = NULL)

head(r_wide[, 1:5, with = FALSE])

vector_users <- r_wide[, user_id]
r_wide <- r_wide[ ,user_id := NULL]

# have the column names equal to the item names
setnames(x = r_wide,
         old = names(r_wide),
         new = substring(names(r_wide), 7))

matrix_wide <- as.matrix(r_wide)
rownames(matrix_wide) <- vector_users
head(matrix_wide[, 1:6])


# coercing matrix_wide into a binary rating matrix 
ratings_matrix <- as(matrix_wide, "realRatingMatrix")
ratings_matrix
```


```{r}
# Train and test
which_train <- sample(x = c(TRUE, FALSE),
                      size = nrow(ratings_matrix),
                      replace = TRUE,
                      prob = c(0.7, 0.3))
recc_data_train <- ratings_matrix[which_train, ]
recc_data_test <- ratings_matrix[!which_train, ]

eval_sets <- evaluationScheme(data = ratings_matrix, 
                              method = "split",
                              train = percentage_training, 
                              given = items_to_keep, 
                              goodRating =rating_threshold, 
                              k = n_eval) 

models_to_evaluate <- list(
  IBCF_jac = list(name = "IBCF", param = list(method = "jaccard")),
  IBCF_cos = list(name = "IBCF", param = list(method = "cosine")),
  IBCF_cor = list(name = "IBCF", param = list(method = "pearson")),
  IBCF_euc = list(name = "IBCF", param = list(method = "euclidean")),
  
  UBCF_jac = list(name = "UBCF", param = list(method = "jaccard")),
  UBCF_cos = list(name = "UBCF", param = list(method = "cosine")),
  UBCF_cor = list(name = "UBCF", param = list(method = "pearson")),
  UBCF_euc = list(name = "UBCF", param = list(method = "euclidean"))
#  ,random = list(name = "RANDOM", param=NULL)
)

list_results <- evaluate(x = eval_sets, 
                         method = models_to_evaluate,
                         n = n_recommendations)

class(list_results)

# Calculate the ROC curve
plot(list_results, legend = "topleft",ylim = c(0, 0.35)) 
title("ROC curve - rating models")

# Calculate the precision and recall
plot(list_results, "prec/rec", legend = "bottomleft")
title("Precision-recall rating models")

# average confusion matrix
avg_matrices <- lapply(list_results, avg)

# IBCF cosine distance
head(avg_matrices$IBCF_cos[,1:8])


# IBCF Pearson correlation
head(avg_matrices$IBCF_cor[, 1:8])

# IBCF jaccard
head(avg_matrices$IBCF_jac[, 1:8])

# IBCF Eucliden
head(avg_matrices$IBCF_euc[, 1:8])

# UBCF cosine distance
head(avg_matrices$UBCF_cos[, 1:8])

# UBCF jaccard
head(avg_matrices$UBCF_jac[, 1:8])

# UBCF euclidean
head(avg_matrices$UBCF_euc[, 1:8])

# UBCF correlation
head(avg_matrices$UBCF_cor[, 1:8])

```

